---
layout: post
title: CPU上下文切换
categories: [Linux]
---

> 破山中贼易，破心中贼难

Linux是一个多任务操作系统，它支持远大于逻辑CPU数量的任务同时运行。当然这些任务不是真的同时运行的，而是系统在很短的时间内，将CPU按照时间分片的方式轮流分配给这些任务，由于时间果断，用户无法感知任务的切换运行，造成多个任务同时运行的错觉。

要实现这种效果，必要要保证CPU知道在运行某个任务之前，清楚任务要从哪里加载，又从哪里开始运行。我们把这些信息成为**CPU上下文**。CPU在切换任务时，需要保存前一个任务的上下文，然后加新任务的上下文，最后开始运行新任务，我们成这个过程为**CPU上下文切换**。

根据任务的不同，我们将CPU上下文切换分为三种场景：**进程上下文切换**、**线程上下文切换**以及**中断上下文切换**。在具体介绍这三种上下文切换之前，先补充一些基础概念知识。

## 用户空间和内核空间

在CPU的所有指令中，有些指令是非常危险的，如果错用会导致操作系统的崩溃，比如清理内存、设置时钟等操作。为了提高操作系统的稳定性 ，只允许操作系统及其相关模块使用这些危险的CPU指令。比如Intel的CPU将指令的特权等级分为4个级别： Ring0~Ring3.

现代操作系统都采用虚拟存储进行存储管理。操作系统将虚拟存储空间分为两部分：内核空间和用户空间。内核空间供内核使用，而用户空间供普通用户进程使用。操作系统的核心是内核(kernel),独立于普通的应用程序，拥有访问受保护的内存空间及底层硬件设备的所有权限。

从以上的描述中，我们可以知道：

<font color="#dd0000">内核空间存放的是内核代码和数据，而用户空间存放的是用户程序的代码和数据。不管内核空间还是用户空间，它们都处于虚拟空间中。</font>

## 用户态和内核态

- 当一个任务(进程)执行**系统调用**陷入内核代码中执行时，称进程处于内核运行态(内核态)
  
  此时处理器处于特权最高(Ring0)的内核代码中执行。当进程处于内核态时，执行的内核代码会使用当前进程的内核栈。每个进程都有自己的内核栈。

- 当进程在执行用户自己的代码时，则称其处于用户运行态(用户态)。此时处理器在特权级最低的(3级)用户代码中执行。当正在执行的用户程序被中断程序中断时，此时用户程序也可以象征性的称为处于进程的内核台态，因为中断处理程序将使用当前进程的内核栈。

注意：在某些实现中，中断服务程序不在进程的上下文中执行，它们在一个与所有进程都无关的、专门的中断上下文中执行。之所以存在一个专门的执行环境，就是为了保证中断服务程序能够在第一时间响应和处理中断请求，然后快速地退出。


<font color="#dd0000">用户态进入内核态</font>

系统的所有资源管理都是在内核空间完成的，比如读写磁盘文件、分配回收内存及从网络接口读写数据等等。用户程序无法直接进行这些操作，只能通过内核提供的相关接口完成这些任务。用户运行态的进程通过执行特殊的指令进入内核态，在内核空间中CPU可以执行任何指令，经目标数据读到内核空间中，然后将数据拷贝到用户空间并从内核态切换到用户态。系统提供了**系统调用、软中断和硬件中断**三种方式实现用户态到内核态的切换。

![用户态到内核态的切换](http://blog.linyimin.club/images/posts/linux-analysis/用户态到内核态的切换.png)

根据上面的基础概念知识，我们可以知道，进程既可以在用户空间中运行，也可以在内核空间中运行。一般情况下，通过**系统调用**完成用户态到内核态的转换.

系统调用的过程需要完成两次CPU上下文切换.一开始,CPU运行用户空间的代码,寄存器中保存的是用户态的状态信息和相关数据, 在切换到内核态之前需要保存相关上下文,然后加载内核态的上下文,最后在内核空间中运行相关内核任务,此时完成一次CPU上下文切换,当内核态执行完成之后,需要返回用户空间运行,此时又发生一次上下文切换,所以一次完整的系统调用需要两次CPU上下文切换.

需要注意的是: <font color="#dd0000">系统调用是在一个进程里完成的,所以上下文不会涉及到虚拟内存等资源的切换</font>

下面开始具体介绍三种类型的上下文切换

## 进程上下文切换

由此可知,进程上下文切换和系统调用的上下文切换是不一样的:

- 进程上下问切换是指从一个进程切换到另一个进程执行
- 系统调用过程一直是在同一个进程中执行的

所以,<font color="#dd0000">系统调用过程通常成为**特权模式切换**,而不是上下文切换</font>

进程由内核来管理和调度,且切换只能发生在内核态,所以进程的上下文不仅包括: 虚拟内存空间、栈全局变量等用户空间的资源，还包括内核堆栈、寄存器等内核空间的状态。

所以与，系统调换相比，进程的上下文切换的不同之处在于： 在保存当前进程的内核状态和CPU寄存器之前，还需要将该进程的虚拟内存、堆栈等保存下来，切换到新的进程之后还需要加载新进程的虚拟内存和用户栈等数据。

![进程上下文切换时间](http://blog.linyimin.club/images/posts/linux-analysis/进程上下文切换时间.png)

### 发生进程调度的时机

- 进程的CPU时间片耗尽，系统将其挂起，切换到准备就绪队列中正在等待CPU的其他进程；
- 进程需要的系统资源不足，系统将其挂起，切换到准备就绪队列中正在等待CPU的其他进程；
- 进程通过Sleep等函数将自己挂起，系统也会开始重新调度；
- 当有优先级更高的进程需要运行时，也会发生进程调度；
- 发生硬件中断时，也会发生进程调度，转至执行内核中的中断服务程序。

## 线程上下文切换

线程和进程的最大区别在于： <font color="#dd0000">线程是CPU的基本调度单位，进程的是资源拥有的基本单位</font>

所以，内核中的任务调度，调度的对象实际上是线程，而进程只是给线程提供了虚拟内存、全局变量、堆栈等资源。所以对于线程和进程我们可以这么理解：

- 当进程只有一个线程时，可以认为线程就是进程；
- 当进程拥有对个线程时，这些线程会共享相同的虚拟内存和全局变量等资源，在同一进程中的线程切换时这些资源是不需要修改的；
- 线程拥有自己的私有数据，比如栈和寄存器。

所以对于线程上下文切换可以分两种情况考虑：

1. 切换的前后两个线程不属于一个进程，那么线程切换等价与进程切换
2. 前后线程属于同一个进程，则只需要切换线程的私有数据，共享的数据不需要交换。


可以发现，同进程内的线程切换比进程间的切换消耗的资源更少，这也是使用多线程替代多进程的一个巨大优势。

## 中断上下文切换

为了快速响应硬件的事件，中断处理会打断进程的正常调度和执行，转而执行中断服务程序。发生中断时，中断程序就在独立内核空间中，在内核状态下执行中断服务程序。所以不需要保存进程的虚拟内存空间，全局变量等用户资源，只需要保存CPU寄存器，被中断程序下一条指令地址等数据，在中断服务程序执行完成之后，返回被中断程序继续执行。

## 小结

根据上面的分析，我们可以知道：

1. CPU上下文切换是保证Linux系统正常工作的核心功能之一，但是用户需要特别关注；
2. 过多的CPU上下文切换，会把大量的CPU时间消耗寄存器、内核栈及虚拟内存数据的保存和恢复上，而进程真正运行时间大大减少，会导致系统的整体性能大幅下降。

## 实际案例分析

### 查看系统的上下文切换情况

**使用`vmstat`命令查看**

> Report virtual memory statistics

```shell
$ vmstat 5 3 # 5秒显示一次，一共显示3次
```

重要字段说明：

- r: The number of runnable processes(running or waiting for run time)
- b: The number of processes in uninterruptible sleep
- in: The number of interrupts per second, including the clock
- cs: The number of context switches per second.

![vmstat查看系统上下文切换情况](http://blog.linyimin.club/images/posts/linux-analysis/vmstat.png)

由执行结果可以知道，最后上下文切换次数是1825次，中断次数为734次，就绪队列长度和不可中断进程数均为0

### 查看指定进程的上下文切换情况

**使用`pidstat`命令查看**

```shell
$ pidstat -p PID -w
```

相关字段说明

- cswch/s: 每秒自愿上下文切换次数
- nvcswch/s: 每秒非自愿上下文切换次数

自愿上下文切换: **进程无法获取所需的系统资源，导致的上下文切换**。比如说， I/O、内存等系统资源不足时，就会发生自愿上下文切换。
非自愿上下文切换: **进程由于时间片已到或者其他原因，被系统强制调度，进而发生的上下文切换** 。比如说大量进程都在争抢CPU时，就容易发生非自愿上下文却换。

![查看指定进程的上下文切换情况](http://blog.linyimin.club/images/posts/linux-analysis/pid-process-cs.png)

由执行结果我们可以知道，PID为5785的进程，自愿上下文切换为0.6次每秒，没有发生非自愿上下文切换

<font ccolor="#dd0000">注意，上面是针对进程的，如果想查看线程级别的上下文切换次数，需要添加上`-t`选项</font>

```shell
$ pidstat -wt -p 5785
```

![查看指定进程内线程上下文切换](http://blog.linyimin.club/images/posts/linux-analysis/pidstat-thread-cs.png)

从执行结果中，我们可以看到，PID为5785的进程中，多线程之间的上下文切换情况

### 实际例子

下面使用`sysbench`来模拟系统多线程调度情况

```shell
# 以10个线程运行5分钟的基准测试，模拟多线程切换问题
$ sysbench --threads=10 --max-time=300 --max-requests=10000000 --test=threads run
```

首先，先查看空闲状态下，系统的上下文切换情况

```shell
$ vmstat 5 3
```

![空闲状态下，系统的上下文切换情况](http://blog.linyimin.club/images/posts/linux-analysis/vmstat-start.png)

由运行结果可知，此时系统上下文切换次数为1454次，中断611次

然后使用`sysbench`模拟多线程切换情景

```shell
$ sysbench --threads=10 --max-time=300 --max-requests=10000000 --test=threads run
```

![系统的上下文切换](http://blog.linyimin.club/images/posts/linux-analysis/sysbench-vmstat-cs.png)

可以发现上下文切换从之前的1454次变成了1442055次，而中断的次数也变成了5824次，同时观察其他指标：

- r:就绪序列变成了7，所以肯定会存在很多CPU竞争
- us(user)和sy(system)列: 这两列的CPU使用率达80%多快到90%，其中系统的使用率(sy)高达80%左右，可以知道CPU主要被内核占用
- in: 中断次数页达到了5824次，说明中断处理也有可能是一个潜在的问题

综合这几个系统指标，我们可以知道，系统的就绪队列过长，也就是正在运行和等待CPU的进程数过多，导致了大量的上下文切换，大量的上下文切换导致系统CPU使用率过高。

发现上下文切换次数过多，造成CPU系统使用过高，是造成系统性能问题的主要原因，接下来我们需要确定，是哪些进程造成上下文切换过多的。首先我们使用`pidstat`查看进程间的上下文切换信息

```shell
$ pidstat -w | sort -r -n -k 4 # 对输出信息按照自愿交换列值大小逆序排序
```
![进程间的上下文交换次数](http://blog.linyimin.club/images/posts/linux-analysis/sysbench-process-cs.png)

可以发现，进程间的交换次数合起来远远小于1442055，所以这么多的上下文交换应该是来自同一进程间多线程的上下文交换。为了确定是哪一个进程，我们先使用`top`命令查看具体是哪些进程占用CPU使用率高

```shell
$ top
```

![进程的CPU使用率](http://blog.linyimin.club/images/posts/linux-analysis/top-cpu-utilization.png)

可以发现CPU使用率最高的进程是sysbench,其PID为10738

然后我们使用`pidstat`命令查看线程间的上下文交换次数。



```shell
$ pidstat -wt -p 10738 5
```

![线程间的上下文交换次数](http://blog.linyimin.club/images/posts/linux-analysis/sysbench-threads-cs.png)

可以知道，我们已经找到了上线文切换次数增大的根源。

除了上下文交换次数升高之后，前面我们还发现中断次数大大升高了，这也有可能是影响系统性能的一部分原因，所以接下来我们继续分析：

我们都知道，中断是发生在内核中的，使用`pidstat`命令只能查看进程的相关信息，并不能提供任何中断相关的详细信息。在上一篇博客[平均负载](http://blog.linyimin.club/blog/load-average.html)中我们提到过/proc这个伪文件系统，它为进程和内核提供了一种文件方式的通信接口，所以我们可以通过读取/proc文件夹下的相关文件来获取中断信息。

中断信息存储在`/proc/interrupts`文件中，所以使用一下命令读取

```shell
$ cat /proc/interrupts
```

```
SPU:          0          0          0          0   Spurious interrupts
PMI:        422        423        422        420   Performance monitoring interrupts
IWI:          1         26          0          1   IRQ work interrupts
RTR:          0          0          0          0   APIC ICR read retries
RES:    2686826    2709640    2737088    2719230   Rescheduling interrupts
CAL:     238821     211299     210075     214742   Function call interrupts
TLB:     210009     208988     207839     212447   TLB shootdowns
```

可以发现，变化最明显的是RES，根据RES注解可以知道，这是**重调度中断**(Rescheduling interrupts),所以中断次数升高的原因还是还因为过多的任务调度。


### 每秒交换多少次合适

这个数值取决于系统本身的CPU性能。当上下文交换次数出现指数式增长时，很有可能出现了性能问题，这是需要根据上下文交换的类型进行具体的分析：

- 自愿上下文交换增多： 说明进程都在等待资源，或者发生IO问题
- 非自愿上下文交换增多： 说明进程在强制调度，也就是进程数远远大于CPU逻辑核数，有大量进程在争抢CPU资源
- 中断次数增多： 说明CPU正在被中断处理占用，需要查看`/proc/interrupts`文件来具体分析具体的中断类型。



## 参考链接

[极客时间: Linux性能优化实践](https://time.geekbang.org/column/article/69859)

[Linux内核空间与用户空间](https://www.cnblogs.com/sparkdev/p/8410350.html)

[Linux内核中的中断栈与内核栈的补充说明](https://blog.csdn.net/hovan/article/details/51996603)
